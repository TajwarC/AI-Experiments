{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis using BERT and fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will first perform sentiment analysis using a small language model (BERT), using the media bias dataset. We will then fine tune the model and repeat the analysis, comparing the accuracy of the model before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tchoudhury\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing and viewing data**\n",
    "\n",
    "The dataset we are using can be found here as \"final_labels_sg1\". It is a dataset containing news headlines which have been labelled manually as biased or non-biased, including any potential biased words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>news_link</th>\n",
       "      <th>outlet</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>label_bias</th>\n",
       "      <th>label_opinion</th>\n",
       "      <th>biased_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Republican president assumed he was helpin...</td>\n",
       "      <td>http://www.msnbc.com/rachel-maddow-show/auto-i...</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>environment</td>\n",
       "      <td>left</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Though the indictment of a woman for her own p...</td>\n",
       "      <td>https://eu.usatoday.com/story/news/nation/2019...</td>\n",
       "      <td>usa-today</td>\n",
       "      <td>abortion</td>\n",
       "      <td>center</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ingraham began the exchange by noting American...</td>\n",
       "      <td>https://www.breitbart.com/economy/2020/01/12/d...</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>immigration</td>\n",
       "      <td>right</td>\n",
       "      <td>No agreement</td>\n",
       "      <td>No agreement</td>\n",
       "      <td>['flood']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tragedy of America’s 18 years in Afghanist...</td>\n",
       "      <td>http://feedproxy.google.com/~r/breitbart/~3/ER...</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>international-politics-and-world-news</td>\n",
       "      <td>right</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>['tragedy', 'stubborn']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The justices threw out a challenge from gun ri...</td>\n",
       "      <td>https://www.huffpost.com/entry/supreme-court-g...</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>gun-control</td>\n",
       "      <td>left</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Republican president assumed he was helpin...   \n",
       "1  Though the indictment of a woman for her own p...   \n",
       "2  Ingraham began the exchange by noting American...   \n",
       "3  The tragedy of America’s 18 years in Afghanist...   \n",
       "4  The justices threw out a challenge from gun ri...   \n",
       "\n",
       "                                           news_link     outlet  \\\n",
       "0  http://www.msnbc.com/rachel-maddow-show/auto-i...      msnbc   \n",
       "1  https://eu.usatoday.com/story/news/nation/2019...  usa-today   \n",
       "2  https://www.breitbart.com/economy/2020/01/12/d...  breitbart   \n",
       "3  http://feedproxy.google.com/~r/breitbart/~3/ER...  breitbart   \n",
       "4  https://www.huffpost.com/entry/supreme-court-g...      msnbc   \n",
       "\n",
       "                                   topic    type    label_bias  \\\n",
       "0                            environment    left        Biased   \n",
       "1                               abortion  center    Non-biased   \n",
       "2                            immigration   right  No agreement   \n",
       "3  international-politics-and-world-news   right        Biased   \n",
       "4                            gun-control    left    Non-biased   \n",
       "\n",
       "                           label_opinion             biased_words  \n",
       "0             Expresses writer’s opinion                       []  \n",
       "1  Somewhat factual but also opinionated                       []  \n",
       "2                           No agreement                ['flood']  \n",
       "3  Somewhat factual but also opinionated  ['tragedy', 'stubborn']  \n",
       "4                       Entirely factual                       []  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://docs.google.com/spreadsheets/d/1KKPAiOppopEzbnINsdl-OVR8WOg2ly1a/edit?usp=drive_link&ouid=109883226317661265367&rtpof=true&sd=true'\n",
    "file_id=url.split('/')[-2]\n",
    "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
    "df = pd.read_excel(dwn_url)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running inference from Pre-Trained DistilBERT. Note, we are assuming Non-biased -> positive sentiment and Biased -> negative sentiment\n",
    "\n",
    "An off the shelf model is not designed for this task, so we will attempt to fine tune it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take random sample from dataset\n",
    "\n",
    "df_sample = df.sample(n=100, random_state=42).reset_index(drop=True)\n",
    "texts = df_sample[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# Load pre-trained DistilBERT model for sentiment classification\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Predict sentiment for each text\n",
    "predictions = classifier(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_bias</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If she doesn't want to thank him for his honor...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House Democrats’ Chinese coronavirus relief pa...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French sporting goods retailer Decathlon has c...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>That is because much of what Newsom and the De...</td>\n",
       "      <td>No agreement</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple and Google are facing criticism for offe...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Democrats really don’t want to spend billions ...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>That’s why white nationalists, who are enthusi...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hungary is backing President Trump in his crac...</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Non-biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>For the first time since the enactment of the ...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Earlier this year, Freedom to Prosper and Data...</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label_bias  \\\n",
       "0  If she doesn't want to thank him for his honor...        Biased   \n",
       "1  House Democrats’ Chinese coronavirus relief pa...        Biased   \n",
       "2  French sporting goods retailer Decathlon has c...    Non-biased   \n",
       "3  That is because much of what Newsom and the De...  No agreement   \n",
       "4  Apple and Google are facing criticism for offe...    Non-biased   \n",
       "5  Democrats really don’t want to spend billions ...        Biased   \n",
       "6  That’s why white nationalists, who are enthusi...        Biased   \n",
       "7  Hungary is backing President Trump in his crac...        Biased   \n",
       "8  For the first time since the enactment of the ...    Non-biased   \n",
       "9  Earlier this year, Freedom to Prosper and Data...    Non-biased   \n",
       "\n",
       "  predicted_label  \n",
       "0          Biased  \n",
       "1          Biased  \n",
       "2          Biased  \n",
       "3          Biased  \n",
       "4          Biased  \n",
       "5          Biased  \n",
       "6          Biased  \n",
       "7      Non-biased  \n",
       "8          Biased  \n",
       "9          Biased  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping labels (as classification is binary)\n",
    "def map_labels(pred):\n",
    "    if pred[\"label\"] == \"POSITIVE\":\n",
    "        return \"Non-biased\"\n",
    "    elif pred[\"label\"] == \"NEGATIVE\":\n",
    "        return \"Biased\"\n",
    "    else:\n",
    "        return \"No agreement\" # if confidence is low\n",
    "\n",
    "# Apply mapping to predictions\n",
    "df_sample[\"predicted_label\"] = [map_labels(p) for p in predictions]\n",
    "\n",
    "# Undo mapping from original labels for comparsion\n",
    "#label_mapping = {0:'Biased', 1: \"No agreement\", 2: \"Non-biased\"}\n",
    "#df_sample['label_bias'] = df['label_bias'].map(label_mapping)\n",
    "\n",
    "# Show results\n",
    "df_sample[[\"text\", \"label_bias\", \"predicted_label\"]].head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Biased       0.40      0.71      0.51        41\n",
      "No agreement       0.00      0.00      0.00         9\n",
      "  Non-biased       0.48      0.26      0.34        50\n",
      "\n",
      "    accuracy                           0.42       100\n",
      "   macro avg       0.29      0.32      0.28       100\n",
      "weighted avg       0.40      0.42      0.38       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tchoudhury\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tchoudhury\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\tchoudhury\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df_sample[\"label_bias\"] = df_sample[\"label_bias\"].astype(str)\n",
    "df_sample[\"predicted_label\"] = df_sample[\"predicted_label\"].astype(str)\n",
    "\n",
    "print(classification_report(df_sample[\"label_bias\"], df_sample['predicted_label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map labels\n",
    "label_mapping = {\"Biased\":0, \"No agreement\": 1, \"Non-biased\": 2}\n",
    "df['label_bias'] = df['label_bias'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into HF dataset\n",
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc26a3d58724e5d8ac006cd0f2d923c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenisation\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# DistilBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokens = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    tokens[\"labels\"] = examples[\"label_bias\"]  # Add labels to the tokenized dataset\n",
    "    return tokens\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = tokenized_datasets.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test[\"train\"]\n",
    "val_dataset = train_test[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load model with num_labels set to 3 (for positive, neutral, negative)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='255' max='255' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [255/255 1:16:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.796735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.826373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.922407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=255, training_loss=0.5093984566482843, metrics={'train_runtime': 4627.8624, 'train_samples_per_second': 0.882, 'train_steps_per_second': 0.055, 'total_flos': 623137755856896.0, 'train_loss': 0.5093984566482843, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sentiment-distilbert\\\\tokenizer_config.json',\n",
       " 'sentiment-distilbert\\\\special_tokens_map.json',\n",
       " 'sentiment-distilbert\\\\vocab.txt',\n",
       " 'sentiment-distilbert\\\\added_tokens.json',\n",
       " 'sentiment-distilbert\\\\tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"sentiment-distilbert\")\n",
    "tokenizer.save_pretrained(\"sentiment-distilbert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.463336706161499}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"sentiment-distilbert\", tokenizer=tokenizer)\n",
    "\n",
    "text = df['text'][0]\n",
    "prediction = classifier(text)\n",
    "\n",
    "print(prediction)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
