{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJCCAAuZ47OJ"
      },
      "source": [
        "## Assessing credit risk using various machine learning models\n",
        "\n",
        "In this notebook we will train a few machine learning models on the German Credit scoring dataset. We will perform a fairness assessment using FairLearn to obtain some metadata about each model we have trained. The goal is to then take this metadata and use an LLM to help decide which model(s) are most fair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tlnf63BCVCUc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,log_loss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, classification_report, RocCurveDisplay\n",
        "import itertools\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "import warnings                   # to deal with warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "EblQQ1KQVXhO",
        "outputId": "a4550b18-127c-4966-ab7b-60c2080a62d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Job</th>\n",
              "      <th>Housing</th>\n",
              "      <th>Saving accounts</th>\n",
              "      <th>Checking account</th>\n",
              "      <th>Credit amount</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Purpose</th>\n",
              "      <th>Risk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "      <td>male</td>\n",
              "      <td>2</td>\n",
              "      <td>own</td>\n",
              "      <td>none</td>\n",
              "      <td>little</td>\n",
              "      <td>1169</td>\n",
              "      <td>6</td>\n",
              "      <td>radio/TV</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>female</td>\n",
              "      <td>2</td>\n",
              "      <td>own</td>\n",
              "      <td>little</td>\n",
              "      <td>moderate</td>\n",
              "      <td>5951</td>\n",
              "      <td>48</td>\n",
              "      <td>radio/TV</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>49</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>own</td>\n",
              "      <td>little</td>\n",
              "      <td>none</td>\n",
              "      <td>2096</td>\n",
              "      <td>12</td>\n",
              "      <td>education</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>45</td>\n",
              "      <td>male</td>\n",
              "      <td>2</td>\n",
              "      <td>free</td>\n",
              "      <td>little</td>\n",
              "      <td>little</td>\n",
              "      <td>7882</td>\n",
              "      <td>42</td>\n",
              "      <td>furniture/equipment</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>male</td>\n",
              "      <td>2</td>\n",
              "      <td>free</td>\n",
              "      <td>little</td>\n",
              "      <td>little</td>\n",
              "      <td>4870</td>\n",
              "      <td>24</td>\n",
              "      <td>car</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Age     Sex  Job Housing Saving accounts Checking account  \\\n",
              "0           0   67    male    2     own            none           little   \n",
              "1           1   22  female    2     own          little         moderate   \n",
              "2           2   49    male    1     own          little             none   \n",
              "3           3   45    male    2    free          little           little   \n",
              "4           4   53    male    2    free          little           little   \n",
              "\n",
              "   Credit amount  Duration              Purpose  Risk  \n",
              "0           1169         6             radio/TV  good  \n",
              "1           5951        48             radio/TV   bad  \n",
              "2           2096        12            education  good  \n",
              "3           7882        42  furniture/equipment  good  \n",
              "4           4870        24                  car   bad  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View dataframe\n",
        "url='https://drive.google.com/file/d/1IZoVERZH1dSp9zXhlIn8ITQ3CBn8USWp/view?usp=drive_link'\n",
        "file_id=url.split('/')[-2]\n",
        "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
        "df = pd.read_csv(dwn_url)\n",
        "\n",
        "df = df.replace({np.nan: 'none'})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZEP0aPT1VqVv"
      },
      "outputs": [],
      "source": [
        "# Separate categorical and numerical features\n",
        "\n",
        "num_df = df[['Age','Job','Duration']]\n",
        "cat_df = df[['Sex','Housing','Saving accounts','Checking account','Credit amount','Purpose','Risk']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "mR0GqtdKWgZa",
        "outputId": "91963482-3d17-40fc-9854-feae4f83a93e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Job</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Housing</th>\n",
              "      <th>Saving accounts</th>\n",
              "      <th>Checking account</th>\n",
              "      <th>Credit amount</th>\n",
              "      <th>Purpose</th>\n",
              "      <th>Risk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>142</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>770</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>390</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>848</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>734</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Job  Duration  Sex  Housing  Saving accounts  Checking account  \\\n",
              "0   67    2         6    1        1                2                 0   \n",
              "1   22    2        48    0        1                0                 1   \n",
              "2   49    1        12    1        1                0                 2   \n",
              "3   45    2        42    1        0                0                 0   \n",
              "4   53    2        24    1        0                0                 0   \n",
              "\n",
              "   Credit amount  Purpose  Risk  \n",
              "0            142        5     1  \n",
              "1            770        5     0  \n",
              "2            390        3     1  \n",
              "3            848        4     1  \n",
              "4            734        1     0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# label encoding\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "for i in cat_df:\n",
        "  cat_df[i] = le.fit_transform(df[i])\n",
        "\n",
        "# Join encoded data to numeric data\n",
        "\n",
        "main_df = pd.concat([num_df, cat_df], axis=1)\n",
        "main_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IR6xeW5iWhsI"
      },
      "outputs": [],
      "source": [
        "# Inputs and outputs\n",
        "\n",
        "X_df = main_df.drop('Risk', axis=1)\n",
        "y = main_df['Risk']\n",
        "\n",
        "# Training and testing splits\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7A97m2S52cY"
      },
      "source": [
        "We now want to choose some models to use and find the best hyperparameters. We can use ```GridSearchCV``` to find the optimal hyperparameters for model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grSWXZtVJl6n",
        "outputId": "d44df85a-375c-459c-8f62-24f94aba4527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
            "{'bootstrap': False, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n"
          ]
        }
      ],
      "source": [
        "# For Random Forest\n",
        "\n",
        "param_grid_RFC = {\n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "grid_RFC = GridSearchCV(RandomForestClassifier(random_state=42),\n",
        "                    param_grid_RFC,\n",
        "                    refit=True,\n",
        "                    verbose=3,\n",
        "                    scoring='accuracy',  # Optimize for accuracy\n",
        "                    n_jobs=-1)  # Use all available cores\n",
        "\n",
        "grid_RFC.fit(X_train, y_train)\n",
        "\n",
        "print(grid_RFC.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Jv3QzXqbEXDx",
        "outputId": "52b575ab-a7fa-4f7d-9615-d0a0f8bb26d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "{'C': 1, 'degree': 1, 'gamma': 'scale', 'kernel': 'linear'}\n"
          ]
        }
      ],
      "source": [
        "# For SVC\n",
        "\n",
        "param_grid_SVC = {'C': [0.1, 1, 5],\n",
        "                  'kernel': ['linear', 'rbf'],\n",
        "                  'degree': [1, 2, 3, 4],\n",
        "                  'gamma' :['scale','auto']}\n",
        "\n",
        "grid_SVC = GridSearchCV(SVC(),\n",
        "                    param_grid_SVC,\n",
        "                    refit=True,\n",
        "                    verbose=3,\n",
        "                    scoring = 'accuracy',\n",
        "                    n_jobs = -1)\n",
        "grid_SVC.fit(X_train, y_train)\n",
        "\n",
        "print(grid_SVC.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "mejymwUgH3UI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        }
      ],
      "source": [
        "# For Linear regression\n",
        "\n",
        "param_grid_LR = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'max_iter': [50, 100, 200, 300]\n",
        "}\n",
        "\n",
        "grid_LR = GridSearchCV(LogisticRegression(),\n",
        "                    param_grid_LR,\n",
        "                    refit=True,\n",
        "                    verbose=3,\n",
        "                    scoring = 'accuracy',\n",
        "                    n_jobs = -1)\n",
        "\n",
        "grid_LR.fit(X_train, y_train)\n",
        "\n",
        "print(grid_LR.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3NMzMFOtOEqM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 2400 candidates, totalling 12000 fits\n",
            "{'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n"
          ]
        }
      ],
      "source": [
        "# XGBoost\n",
        "\n",
        "param_grid_XG = {\n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.025, 0.5, 0.1, 0.15],\n",
        "    'max_depth': [3, 5, 7, 10, 12],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0, 1.2],\n",
        "    'gamma': [0.1, 0.2],\n",
        "}\n",
        "\n",
        "grid_XG = GridSearchCV(XGBClassifier(),\n",
        "                    param_grid_XG,\n",
        "                    refit=True,\n",
        "                    verbose=3,\n",
        "                    scoring='accuracy',  # Optimize for accuracy\n",
        "                    n_jobs = -1)  # Use all available cores\n",
        "\n",
        "grid_XG.fit(X_train, y_train)\n",
        "\n",
        "print(grid_XG.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJP2g4W76i7O"
      },
      "source": [
        "We are now going to use these optimised hyperparameters to train 5 instances of each model type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "93eyaiU9W5qX"
      },
      "outputs": [],
      "source": [
        "num_models = 5\n",
        "\n",
        "RFCS = []\n",
        "for i in range(num_models):\n",
        "  RFC = RandomForestClassifier(**grid_RFC.best_params_)\n",
        "  RFC.fit(X_train, y_train)\n",
        "  RFCS.append(RFC)\n",
        "\n",
        "SVCS = []\n",
        "for i in range(num_models):\n",
        "  classifier = SVC(**grid_SVC.best_params_)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  SVCS.append(classifier)\n",
        "\n",
        "LRS = []\n",
        "for i in range(num_models):\n",
        "  LR = LogisticRegression(**grid_LR.best_params_)\n",
        "  LR.fit(X_train, y_train)\n",
        "  LRS.append(LR)\n",
        "\n",
        "# Does changing the hyperparameters here make any real difference to the fairness?\n",
        "XGBS = []\n",
        "for i in range(num_models):\n",
        "  XGB = XGBClassifier(**grid_XG.best_params_)\n",
        "  XGB.fit(X_train, y_train)\n",
        "  XGBS.append(XGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CftABB7z656q"
      },
      "source": [
        "We can now calculate the accuracy score for each model and place them into an array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkkR2ZBMdH8M",
        "outputId": "4a285e6a-c51b-47ae-a34e-05f675423a63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.775 0.745 0.755 0.74 ]\n",
            " [0.78  0.745 0.755 0.74 ]\n",
            " [0.785 0.745 0.755 0.74 ]\n",
            " [0.765 0.745 0.755 0.74 ]\n",
            " [0.775 0.745 0.755 0.74 ]]\n"
          ]
        }
      ],
      "source": [
        "predictions = []\n",
        "for i in range(num_models):\n",
        "  predictions.append(RFCS[i].predict(X_test))\n",
        "  predictions.append(SVCS[i].predict(X_test))\n",
        "  predictions.append(LRS[i].predict(X_test))\n",
        "  predictions.append(XGBS[i].predict(X_test))\n",
        "\n",
        "accuracy_scores = [accuracy_score(y_test, pred) for pred in predictions]\n",
        "\n",
        "# number of columns of accuracy matrix = number of type of models\n",
        "col_dim = int(len(accuracy_scores)/num_models)\n",
        "\n",
        "# Place accuracy scores into matrix\n",
        "accuracy_matrix = np.array(accuracy_scores).reshape(num_models, col_dim)\n",
        "print(accuracy_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fohR0ObV_GTX"
      },
      "source": [
        "**Conducting a simple fairness assessment using FairLearn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IRnr4cd_bz44"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from fairlearn.metrics import (\n",
        "    MetricFrame,\n",
        "    count,\n",
        "    false_negative_rate,\n",
        "    false_positive_rate,\n",
        "    selection_rate,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VJYDk4g_cJb"
      },
      "source": [
        "We will look at the FPR between men and women for each model as our fairness metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ipnI13Xib8pz"
      },
      "outputs": [],
      "source": [
        "# Select a feature\n",
        "sex = X_test['Sex']#\n",
        "# Select metrics\n",
        "metrics = {\n",
        "    #\"accuracy\": accuracy_score,\n",
        "    #\"precision\": precision_score,\n",
        "    \"false positive rate\": false_positive_rate,\n",
        "    #\"false negative rate\": false_negative_rate,\n",
        "    #\"selection rate\": selection_rate,\n",
        "    #\"count\": count,\n",
        "}\n",
        "metrics_list = []\n",
        "for i in range(len(predictions)):\n",
        "\n",
        "    FPRS = MetricFrame(\n",
        "        metrics=metrics,\n",
        "        y_true=y_test,\n",
        "        y_pred=predictions[i],\n",
        "        sensitive_features=sex,\n",
        "    )\n",
        "    metrics_list.append(FPRS.by_group.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL0_KCXb_jWh"
      },
      "source": [
        "Now that we have an accuracy score and a fairness metric for each model, we want to arrange them into arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXfmhcl44JlY",
        "outputId": "6939a5f4-6dd2-4cad-9a7a-cc9df564c3f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[0.5   0.55 ]\n",
            "  [0.7   0.75 ]\n",
            "  [0.7   0.7  ]\n",
            "  [0.5   0.6  ]]\n",
            "\n",
            " [[0.55  0.55 ]\n",
            "  [0.7   0.75 ]\n",
            "  [0.7   0.7  ]\n",
            "  [0.5   0.6  ]]\n",
            "\n",
            " [[0.5   0.575]\n",
            "  [0.7   0.75 ]\n",
            "  [0.7   0.7  ]\n",
            "  [0.5   0.6  ]]\n",
            "\n",
            " [[0.55  0.6  ]\n",
            "  [0.7   0.75 ]\n",
            "  [0.7   0.7  ]\n",
            "  [0.5   0.6  ]]\n",
            "\n",
            " [[0.55  0.6  ]\n",
            "  [0.7   0.75 ]\n",
            "  [0.7   0.7  ]\n",
            "  [0.5   0.6  ]]]\n"
          ]
        }
      ],
      "source": [
        "FPRS_matrix = np.array(metrics_list).reshape(num_models,col_dim,2)  # first dimension is the umber of sub arrays, equal to the number of models\n",
        "# second dimension is the number of model types\n",
        "# third dimension is the number of features in the FPR calculation, i.e. male/female\n",
        "print(FPRS_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz8hMCZ_55ZL",
        "outputId": "44c21af3-5948-456b-cecc-f74cf3996cc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[0.5   0.55 ]\n",
            "  [0.55  0.55 ]\n",
            "  [0.5   0.575]\n",
            "  [0.55  0.6  ]\n",
            "  [0.55  0.6  ]]\n",
            "\n",
            " [[0.7   0.75 ]\n",
            "  [0.7   0.75 ]\n",
            "  [0.7   0.75 ]\n",
            "  [0.7   0.75 ]\n",
            "  [0.7   0.75 ]]\n",
            "\n",
            " [[0.7   0.7  ]\n",
            "  [0.7   0.7  ]\n",
            "  [0.7   0.7  ]\n",
            "  [0.7   0.7  ]\n",
            "  [0.7   0.7  ]]\n",
            "\n",
            " [[0.5   0.6  ]\n",
            "  [0.5   0.6  ]\n",
            "  [0.5   0.6  ]\n",
            "  [0.5   0.6  ]\n",
            "  [0.5   0.6  ]]]\n"
          ]
        }
      ],
      "source": [
        "# Reshape the array so each sub array corresponds to one model type\n",
        "grouped_rows = [FPRS_matrix[:, i, :] for i in range(FPRS_matrix.shape[1])]\n",
        "# Stack the grouped rows into a single 3D array\n",
        "combined_array = np.stack(grouped_rows, axis=0)\n",
        "print(combined_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kTPxKUs6IvB",
        "outputId": "4487c7eb-df0e-4797-d956-af04936ad2fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.785 0.745 0.755 0.79 ]\n",
            " [0.77  0.745 0.755 0.79 ]\n",
            " [0.775 0.745 0.755 0.79 ]\n",
            " [0.765 0.745 0.755 0.79 ]\n",
            " [0.775 0.745 0.755 0.79 ]]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuHXEBrb_qlM"
      },
      "source": [
        "Given an array containing information about the accuracy score of each model, and fairness metrics about each model, can an LLM provide a useful insight into which model is best with respect to accuracy and fairness? How can we prompt a model to give us this information?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-LiTB_Rx66ec"
      },
      "outputs": [],
      "source": [
        "# combined_array is an array containing the FPR rates for either gender for each model\n",
        "\n",
        "# [[[{FPR for males} {FPR for females}\n",
        "#    [{FPR for males} {FPR for feamles}]...\n",
        "#    ]]]\n",
        "\n",
        "# Where each sub array represents one type of model (e.g. linear regression) and each row in each sub-array represents a specific instance of the type of model\n",
        "# There are 4 model types, Random Forest, SVM, Linear Regression and XGBoost.\n",
        "# There are 5 instances of each model type.\n",
        "# Each row in the sub array represents the false positive rate for males and females respectively for each model\n",
        "\n",
        "# accuracy_matrix is an array containing the accuracy score for each model.\n",
        "# each column represents a model type, in the same order as  Random Forest, SVM, Linear Regression and XGBoost.\n",
        "# Each row is an instance of each model type, there are 5 total."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7vUuTCzGWLv"
      },
      "source": [
        "The following array contains accuracy scores for 4 types of machine learning model. There are 5 instances of each model. Each column represents a model and each row represents an instance of that model. The first column is Random Forest, the second is SVM, the third is linear regression and the fourth is XGBoost.\n",
        "\n",
        "```[[0.77  0.7   0.74  0.795]\n",
        " [0.79  0.7   0.74  0.795]\n",
        " [0.775 0.7   0.74  0.795]\n",
        " [0.77  0.7   0.74  0.795]\n",
        " [0.765 0.7   0.74  0.795]]\n",
        "\n",
        " ```\n",
        " The next array contains information about the false positive rates (FPR) of the models. Each sub array contains the FPRs of one type of model. The first column in each sub array is the FPR with respect to men, and the second column is the FPR with respect to women. Each row in each sub array corresponds to an instance of the model type, and each sub array corresponds to the model type, i.e. the first sub array is for Random forest, the second for SVM, the third for linear regression and the fourth for XGBoost.\n",
        "\n",
        " ```\n",
        "\n",
        "[[[0.5   0.525]\n",
        "  [0.5   0.525]\n",
        "  [0.5   0.5  ]\n",
        "  [0.5   0.475]\n",
        "  [0.5   0.475]]\n",
        "\n",
        " [[1.    1.   ]\n",
        "  [1.    1.   ]\n",
        "  [1.    1.   ]\n",
        "  [1.    1.   ]\n",
        "  [1.    1.   ]]\n",
        "\n",
        " [[0.7   0.7  ]\n",
        "  [0.7   0.7  ]\n",
        "  [0.7   0.7  ]\n",
        "  [0.7   0.7  ]\n",
        "  [0.7   0.7  ]]\n",
        "\n",
        " [[0.45  0.625]\n",
        "  [0.45  0.625]\n",
        "  [0.45  0.625]\n",
        "  [0.45  0.625]\n",
        "  [0.45  0.625]]]\n",
        "\n",
        "```\n",
        "\n",
        "Which model from this information above provides the best tradeoff between accuracy and fairness?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sg1CVvL9P4Wh"
      },
      "outputs": [],
      "source": [
        "# print FPR and other metrics\n",
        "\n",
        "# train multiple models to obtain a model space\n",
        "\n",
        "# use LLM to suggest model parameters to optimise for fairness and accuracy tradeoff\n",
        "\n",
        "# Need to optimise the prompt for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUPA6OIY7MIK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
