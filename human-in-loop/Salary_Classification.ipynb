{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, RocCurveDisplay\n",
    "import itertools\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "import warnings                   # to deal with warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  salary  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View dataframe\n",
    "url='https://drive.google.com/file/d/1fC0xJhngpnQ20xenGxxXViHuqj0ifJcO/view?usp=drive_link'\n",
    "file_id=url.split('/')[-2]\n",
    "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
    "df = pd.read_csv(dwn_url)\n",
    "\n",
    "df = df.replace({np.nan: 'none'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "print(f'Number of duplicates: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workclass         1836\n",
       "occupation        1843\n",
       "native-country     582\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove extra spaces\n",
    "\n",
    "\n",
    "# apply map applies function to every scalar in the dataframe\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "pd.isna(df).sum()[pd.isna(df).sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.workclass.fillna(value='UnknCl', inplace=True)\n",
    "df.occupation.fillna(value='UnknOc', inplace=True)\n",
    "df['native-country'].fillna(value='Unkn_ctry' , inplace=True)\n",
    "\n",
    "## Now check whether the modification has been made or not\n",
    "\n",
    "pd.isna(df).sum()[pd.isna(df).sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "workclass\n",
      "['Govt.' 'self_emp' 'Private' 'UnknCl']\n",
      "\n",
      "education\n",
      "['Bachelors' 'HS-grad' '11th' 'Masters' '9th' 'Some-college' 'Assoc-acdm'\n",
      " 'Assoc-voc' '7th-8th' 'Doctorate' 'Prof-school' '5th-6th' '10th'\n",
      " '1st-4th' 'Preschool' '12th']\n",
      "\n",
      "marital-status\n",
      "['Never-married' 'Married' 'DASW']\n",
      "\n",
      "occupation\n",
      "['Adminstration' 'Executive' 'Handlers' 'Profsiionals' 'UnknOc' 'Sales'\n",
      " 'Repairing' 'Transportation' 'Farming' 'MachineOp' 'Tech-support'\n",
      " 'ProtectiveServ' 'Armed-Forces' 'HouseServ']\n",
      "\n",
      "relationship\n",
      "['Not-in-family' 'Husband' 'Wife' 'Own-child' 'Unmarried' 'Other-relative']\n",
      "\n",
      "race\n",
      "['White' 'Black' 'APAC' 'NatAm' 'Other']\n",
      "\n",
      "sex\n",
      "['Male' 'Female']\n",
      "\n",
      "native-country\n",
      "['USA' 'Cuba' 'Jamaica' 'India' 'Unkn_ctry' 'Mexico' 'SouthKorea'\n",
      " 'PuertoRico' 'Honduras' 'England' 'Canada' 'Germany' 'Iran' 'Philippines'\n",
      " 'Italy' 'Poland' 'Columbia' 'Cambodia' 'Thailand' 'Ecuador' 'Laos'\n",
      " 'Taiwan' 'Haiti' 'Portugal' 'DominicRep' 'El-Salvador' 'France'\n",
      " 'Guatemala' 'China' 'Japan' 'Yugoslavia' 'Peru' 'OutlyingUSA' 'Scotland'\n",
      " 'Tri&Tob' 'Greece' 'Nicaragua' 'Vietnam' 'HongKong' 'Ireland' 'Hungary'\n",
      " 'Netherlands']\n",
      "\n",
      "salary\n",
      "['<=50K' '>50K']\n"
     ]
    }
   ],
   "source": [
    "# Prune labels\n",
    "\n",
    "# df.replace({'category' : {'label' : 'label it is replaced with'})\n",
    "\n",
    "\n",
    "df.replace({'workclass': {'State-gov': 'Govt.', 'Self-emp-not-inc': 'self_emp', 'Federal-gov': 'Govt.', 'Local-gov': 'Govt.', 'Self-emp-inc':'self_emp', 'Without-pay': 'UnknCl', 'Never-worked': 'UnknCl'}}, inplace=True)\n",
    "df.replace({'marital-status': {'Married-civ-spouse': 'Married', 'Divorced': 'DASW', 'Married-spouse-absent': 'DASW', 'Separated': 'DASW', 'Married-AF-spouse':'Married', 'Widowed': 'DASW'}}, inplace=True)\n",
    "df.replace({'occupation': {'Adm-clerical': 'Adminstration', 'Exec-managerial': 'Executive', 'Handlers-cleaners': 'Handlers', 'Prof-specialty': 'Profsiionals', 'Other-service' : 'UnknOc', 'Craft-repair' : 'Repairing', 'Farming-fishing' : 'Farming', 'Transport-moving':'Transportation', 'Machine-op-inspct': 'MachineOp', 'Protective-serv' : 'ProtectiveServ', 'Priv-house-serv': 'HouseServ'}}, inplace=True)\n",
    "df.replace({'native-country': {'United-States': 'USA', 'South': 'SouthKorea', 'Puerto-Rico': 'PuertoRico', 'Dominican-Republic': 'DominicRep', 'Outlying-US(Guam-USVI-etc)':'OutlyingUSA', 'Trinadad&Tobago': 'Tri&Tob', 'Holand-Netherlands': 'Netherlands', 'Hong' : 'HongKong'}}, inplace=True)\n",
    "df.replace({'race': {'Asian-Pac-Islander': 'APAC', 'Amer-Indian-Eskimo': 'NatAm'}}, inplace=True)\n",
    "## df.replace({'salary': {'<=50K': 0, '>50K': 1}}, inplace=True)\n",
    "\n",
    "## Checking whether the modification has been made or not\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype=='object':\n",
    "        print()\n",
    "        print(col)\n",
    "        print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating features into numerical and categorical\n",
    "num_df = df[['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']]\n",
    "cat_df = df[['workclass', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex','native-country', 'salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for i in cat_df:\n",
    "  cat_df[i] = le.fit_transform(df[i])\n",
    "\n",
    "# Join encoded data to numeric data\n",
    "\n",
    "main_df = pd.concat([num_df, cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03</td>\n",
       "      <td>77516</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.84</td>\n",
       "      <td>83311</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>1.13</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>215646</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.06</td>\n",
       "      <td>234721</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-2.40</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-2.31</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.78</td>\n",
       "      <td>338409</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>1.13</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>2.21</td>\n",
       "      <td>-2.31</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  fnlwgt  capital-gain  capital-loss  hours-per-week  workclass  \\\n",
       "0  0.03   77516          0.02          0.00           -0.04       0.00   \n",
       "1  0.84   83311          0.00          0.00           -2.22       1.00   \n",
       "2 -0.04  215646          0.00          0.00           -0.04       0.33   \n",
       "3  1.06  234721          0.00          0.00           -0.04       0.33   \n",
       "4 -0.78  338409          0.00          0.00           -0.04       0.33   \n",
       "\n",
       "   education  education-num  marital-status  occupation  relationship  race  \\\n",
       "0      -0.34           1.13            1.22       -1.66         -0.28  0.40   \n",
       "1      -0.34           1.13           -0.16       -1.20         -0.90  0.40   \n",
       "2       0.18          -0.42           -1.54       -0.73         -0.28  0.40   \n",
       "3      -2.40          -1.20           -0.16       -0.73         -0.90 -2.31   \n",
       "4      -0.34           1.13           -0.16       -0.04          2.21 -2.31   \n",
       "\n",
       "    sex  native-country  salary  \n",
       "0  0.70            0.93       0  \n",
       "1  0.70            0.93       0  \n",
       "2  0.70            0.93       0  \n",
       "3  0.70            0.93       0  \n",
       "4 -1.42            0.10       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxsca = MinMaxScaler() # Normalization\n",
    "stdsca = StandardScaler() # Standardization\n",
    "\n",
    "main_df['marital-status'] = stdsca.fit_transform(main_df[['marital-status']])\n",
    "main_df['sex'] = stdsca.fit_transform(main_df[['sex']])\n",
    "main_df['relationship'] = stdsca.fit_transform(main_df[['relationship']])\n",
    "main_df['hours-per-week'] = stdsca.fit_transform(main_df[['hours-per-week']])\n",
    "main_df['age'] = stdsca.fit_transform(main_df[['age']])\n",
    "main_df['education'] = stdsca.fit_transform(main_df[['education']])\n",
    "main_df['occupation'] = stdsca.fit_transform(main_df[['occupation']])\n",
    "main_df['education-num'] = stdsca.fit_transform(main_df[['education-num']])\n",
    "\n",
    "main_df['workclass'] = minmaxsca.fit_transform(main_df[['workclass']])\n",
    "main_df['capital-gain'] = minmaxsca.fit_transform(main_df[['capital-gain']])\n",
    "main_df['capital-loss'] = minmaxsca.fit_transform(main_df[['capital-loss']])\n",
    "main_df['native-country'] = minmaxsca.fit_transform(main_df[['native-country']])\n",
    "main_df['race'] = stdsca.fit_transform(main_df[['race']])\n",
    "\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into dependent and independent variables\n",
    "\n",
    "X = main_df.drop(columns=[\"salary\", \"fnlwgt\", \"education\", \"workclass\", \"native-country\", \"occupation\", \"marital-status\"])\n",
    "y = main_df[\"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "{'bootstrap': False, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# For Random Forest\n",
    "\n",
    "param_grid_RFC = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_RFC = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                    param_grid_RFC,\n",
    "                    refit=True,\n",
    "                    verbose=3,\n",
    "                    cv = 3,\n",
    "                    scoring='accuracy',  \n",
    "                    n_jobs=-1)  \n",
    "\n",
    "grid_RFC.fit(X_train, y_train)\n",
    "\n",
    "print(grid_RFC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# For SVC\n",
    "\n",
    "param_grid_SVC = {'C': [0.1, 0.5, 1],\n",
    "                  'kernel': ['linear', 'rbf'],\n",
    "                  'gamma' :['scale','auto']}\n",
    "\n",
    "grid_SVC = GridSearchCV(SVC(),\n",
    "                    param_grid_SVC,\n",
    "                    refit=True,\n",
    "                    cv = 3,\n",
    "                    verbose=3,\n",
    "                    scoring = 'accuracy',\n",
    "                    n_jobs = -1)\n",
    "grid_SVC.fit(X_train, y_train)\n",
    "\n",
    "print(grid_SVC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "{'C': 1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "# For Linear regression\n",
    "\n",
    "param_grid_LR = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [50, 100, 200, 300]\n",
    "}\n",
    "\n",
    "grid_LR = GridSearchCV(LogisticRegression(),\n",
    "                    param_grid_LR,\n",
    "                    refit=True,\n",
    "                    cv = 3,\n",
    "                    verbose=3,\n",
    "                    scoring = 'accuracy',\n",
    "                    n_jobs = -1)\n",
    "\n",
    "grid_LR.fit(X_train, y_train)\n",
    "\n",
    "print(grid_LR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1080 candidates, totalling 3240 fits\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "param_grid_XG = {\n",
    "    'n_estimators': [50, 75, 100],\n",
    "    'learning_rate': [0.01, 0.025, 0.5, 0.1, 0.15],\n",
    "    'max_depth': [7, 10, 12],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0, 1.2],\n",
    "    'gamma': [0.1, 0.2],\n",
    "}\n",
    "\n",
    "grid_XG = GridSearchCV(XGBClassifier(),\n",
    "                    param_grid_XG,\n",
    "                    refit=True,\n",
    "                    cv = 3,\n",
    "                    verbose=3,\n",
    "                    scoring='accuracy',  # Optimize for accuracy\n",
    "                    n_jobs = -1)  # Use all available cores\n",
    "\n",
    "grid_XG.fit(X_train, y_train)\n",
    "\n",
    "print(grid_XG.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 3\n",
    "\n",
    "RFCS = []\n",
    "for i in range(num_models):\n",
    "  RFC = RandomForestClassifier(**grid_RFC.best_params_)\n",
    "  RFC.fit(X_train, y_train)\n",
    "  RFCS.append(RFC)\n",
    "\n",
    "SVCS = []\n",
    "for i in range(num_models):\n",
    "  classifier = SVC(**grid_SVC.best_params_)\n",
    "  classifier.fit(X_train, y_train)\n",
    "  SVCS.append(classifier)\n",
    "\n",
    "LRS = []\n",
    "for i in range(num_models):\n",
    "  LR = LogisticRegression(**grid_LR.best_params_)\n",
    "  LR.fit(X_train, y_train)\n",
    "  LRS.append(LR)\n",
    "\n",
    "# Does changing the hyperparameters here make any real difference to the fairness?\n",
    "XGBS = []\n",
    "for i in range(num_models):\n",
    "  XGB = XGBClassifier(**grid_XG.best_params_)\n",
    "  XGB.fit(X_train, y_train)\n",
    "  XGBS.append(XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85617701 0.82928703 0.82037492 0.86432084]\n",
      " [0.85648433 0.82928703 0.82037492 0.86432084]\n",
      " [0.85510141 0.82928703 0.82037492 0.86432084]]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in range(num_models):\n",
    "  predictions.append(RFCS[i].predict(X_test))\n",
    "  predictions.append(SVCS[i].predict(X_test))\n",
    "  predictions.append(LRS[i].predict(X_test))\n",
    "  predictions.append(XGBS[i].predict(X_test))\n",
    "\n",
    "accuracy_scores = [accuracy_score(y_test, pred) for pred in predictions]\n",
    "\n",
    "# number of columns of accuracy matrix = number of type of models\n",
    "col_dim = int(len(accuracy_scores)/num_models)\n",
    "\n",
    "# Place accuracy scores into matrix\n",
    "accuracy_matrix = np.array(accuracy_scores).reshape(num_models, col_dim)\n",
    "print(accuracy_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85592092 0.82928703 0.82037492 0.86432084]\n"
     ]
    }
   ],
   "source": [
    "# Reduce dimension by taking average\n",
    "\n",
    "average_accuracies = np.mean(accuracy_matrix, axis=0)\n",
    "print(average_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    count,\n",
    "    false_negative_rate,\n",
    "    false_positive_rate,\n",
    "    selection_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_feature = X_test['race']\n",
    "\n",
    "# Select metrics\n",
    "metrics = {\n",
    "    \"false positive rate\": false_positive_rate\n",
    "}\n",
    "metrics_list_FPRS = []\n",
    "for i in range(len(predictions)):\n",
    "\n",
    "    FPRS = MetricFrame(\n",
    "        metrics=metrics,\n",
    "        y_true=y_test,\n",
    "        y_pred=predictions[i],\n",
    "        sensitive_features = sens_feature,\n",
    "    )\n",
    "    metrics_list_FPRS.append(FPRS.by_group.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"false_negative_rate\": false_negative_rate\n",
    "}\n",
    "metrics_list_FNRS = []\n",
    "for i in range(len(predictions)):\n",
    "    FNRS = MetricFrame(\n",
    "        metrics = metrics,\n",
    "        y_true = y_test,\n",
    "        y_pred = predictions[i],\n",
    "        sensitive_features = sens_feature \n",
    "    )\n",
    "    metrics_list_FNRS.append(FNRS.by_group.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPRS_matrix = np.array(metrics_list_FPRS).reshape(num_models,col_dim,FPRS.by_group.values.size)\n",
    "FNRS_matrix = np.array(metrics_list_FNRS).reshape(num_models,col_dim,FNRS.by_group.values.size)  \n",
    "# first dimension is the umber of sub arrays, equal to the number of models\n",
    "# second dimension is the number of model types\n",
    "# third dimension is the number of features in the FPR calculation, i.e. male/female\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08888889 0.1037037  0.05185185 0.07407407]\n",
      " [0.00929368 0.00929368 0.02230483 0.01486989]\n",
      " [0.01886792 0.03773585 0.01886792 0.01886792]\n",
      " [0.04347826 0.04347826 0.04347826 0.02173913]\n",
      " [0.04038708 0.05662188 0.06238004 0.06645873]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the array so each sub array corresponds to one model type\n",
    "grouped_rows_FPRS = [FPRS_matrix[:, i, :] for i in range(FPRS_matrix.shape[1])]\n",
    "# Stack the grouped rows into a single 3D array\n",
    "combined_array_FPRS = np.stack(grouped_rows_FPRS, axis=0)\n",
    "#print(combined_array_FPRS)\n",
    "# Mean of combined array\n",
    "average_FPRS = np.mean(combined_array_FPRS, axis = 1)\n",
    "#average_FPRS = np.ravel(average_FPRS)\n",
    "print(average_FPRS.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41843972 0.4893617  0.63829787 0.36170213]\n",
      " [0.58333333 0.73611111 0.68055556 0.47222222]\n",
      " [0.22222222 0.66666667 0.33333333 0.16666667]\n",
      " [0.8        1.         1.         0.8       ]\n",
      " [0.47450162 0.53337969 0.55702364 0.36856745]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the array so each sub array corresponds to one model type\n",
    "grouped_rows_FNRS = [FNRS_matrix[:, i, :] for i in range(FNRS_matrix.shape[1])]\n",
    "# Stack the grouped rows into a single 3D array\n",
    "combined_array_FNRS = np.stack(grouped_rows_FNRS, axis=0)\n",
    "#print(combined_array_FNRS)\n",
    "# Mean of combined array\n",
    "average_FNRS = np.mean(combined_array_FNRS, axis = 1)\n",
    "print(average_FNRS.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the following arrays.\n",
    "\n",
    "Each column represents the accuracy score of a model. The first column is the score for Random Forest, the second column is the score for SVM, the third column is the score for Linear Regression and the fourth column is for XGBoost.\n",
    "\n",
    "[0.85592092 0.82928703 0.82037492 0.86432084]\n",
    "\n",
    "The next array contains the false positive rates (FPRs) for 5 different groups, group 1, group 2, group 3, group 4 and group 5. Each column The first column is the FPR for Random Forest, the second column is the FPR for SVM, the third column is the FPR for Linear Regression and the fourth column is the FPR for XGBoost. Each row represents one of the 5 groups.\n",
    "\n",
    "[[0.08888889 0.1037037  0.05185185 0.07407407]\n",
    " [0.00929368 0.00929368 0.02230483 0.01486989]\n",
    " [0.01886792 0.03773585 0.01886792 0.01886792]\n",
    " [0.04347826 0.04347826 0.04347826 0.02173913]\n",
    " [0.04038708 0.05662188 0.06238004 0.06645873]]\n",
    "\n",
    "The next array contains the false negative rates (FNRs) for 5 different groups, group 1, group 2, group 3, group 4 and group 5. Each column The first column is the FNR for Random Forest, the second column is the FNR for SVM, the third column is the FNR for Linear Regression and the fourth column is the FNR for XGBoost. Each row represents one of the 5 groups.\n",
    "\n",
    "\n",
    "[[0.41843972 0.4893617  0.63829787 0.36170213]\n",
    " [0.58333333 0.73611111 0.68055556 0.47222222]\n",
    " [0.22222222 0.66666667 0.33333333 0.16666667]\n",
    " [0.8        1.         1.         0.8       ]\n",
    " [0.47450162 0.53337969 0.55702364 0.36856745]]\n",
    "\n",
    "Do not perform any calculations or write code. Using the information in the arrays, which model provides the best trade-off between accuracy and fairness based on the FPRs and FNRs? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
